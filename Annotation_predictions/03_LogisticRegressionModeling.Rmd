---
title: "Multinomial logistic regression modeling"
author: "Ngoc Bui and Alexander Romanus"
date: "`r Sys.Date()`"
output: html_document
---



```{r load and clean data, warning=FALSE, message=FALSE}
source("helper_functions.R")
library(caret)
library(pROC)
library(dplyr)
library(VGAM)

train <- read.csv("../Data/Meta/meta_annotation_info_train.csv", header = TRUE)
test <- read.csv("../Data/Meta/meta_annotation_info_test.csv", header = TRUE)

# eliminate all columns that have to do with Malignancy and the response var

non_train_columns = c("Patient_id", "Nodule_no", "Nodule_id", "Annotation_no", "Malignancy_median", "Malignancy_median_high", "Malignancy_entropy",
                      "Malignancy_mode", "Malignancy_mean", "Malignancy")

train_filter <- train[!(names(train) %in% non_train_columns)]

test_filter <- test[!(names(test) %in% non_train_columns)]

```



```{r create-modeling-weights, warning=FALSE, message=FALSE}
ntrain = nrow(train_filter)

nvec = c(table(train_filter$Is_cancer))
wt = rep(1,ntrain)
wt[train_filter$Is_cancer=="Ambiguous"] = (ntrain/4)/nvec[1]
wt[train_filter$Is_cancer=="False"] = (ntrain/4)/nvec[2]
wt[train_filter$Is_cancer=="No_consensus"] = (ntrain/4)/nvec[3]
wt[train_filter$Is_cancer=="True"] = (ntrain/4)/nvec[4]
print(sum(wt)) # same as training set sample size
print(nvec/ntrain)
table(wt)
```
```{r fit-full-model, warning=FALSE, message=FALSE, include=FALSE}
set.seed(42)
fullLogit = vglm(Is_cancer~ ., multinomial(), weights=wt, data=train_filter)
print(summary(fullLogit))
logitFull_pred = predict(fullLogit, type="response", weights=wt, newdata=test_filter)
```



```{r fit-model-selected-variables, warning=FALSE, message=FALSE}
rf_cols = c("Subtlety_mean", "Calcification_mode", "Spiculation_mean", 
"Subtlety_entropy", "Sphericity_mean", "Margin_mean", "Sphericity_entropy", 
"Lobulation_mean", "Lobulation_entropy", "Margin_entropy", "Subtlety_median", 
"Calcification", "Spiculation_entropy", "Subtlety_mode", "Texture_mean", 
"Lobulation_median", "Sphericity_median", "Margin_median", "Texture_entropy", 
"Spiculation_median", "Subtlety_median_high")

set.seed(42)
RFformula = paste("Is_cancer ~ ",paste(rf_cols, collapse="+"),sep = "")
logitRF = vglm(as.formula(RFformula), multinomial(), weights=wt, data=train_filter)
print(summary(logitRF))

logitRF_pred = predictvglm(logitRF, type="response", weights=wt, newdata=test_filter)
```



```{r get-prediction-intervals, warning=FALSE}
predintLogitFull = CategoryPredIntervalNodules(logitFull_pred, labels=c("Ambiguous","False","No_consensus", "True"))
predintLogitRF = CategoryPredIntervalNodules(logitRF_pred, labels=c("Ambiguous","False","No_consensus", "True"))
```

```{r get-coverage-rate-overall, warning=FALSE}
coverage_rate_overall_full_50 = getOverallCoverageRateNodule(predintLogitFull, 50)
coverage_rate_overall_rf_50 = getOverallCoverageRateNodule(predintLogitRF, 50)

coverage_rate_overall_full_80 = getOverallCoverageRateNodule(predintLogitFull, 80)
coverage_rate_overall_rf_80 = getOverallCoverageRateNodule(predintLogitRF, 80)

print(coverage_rate_overall_full_50)
print(coverage_rate_overall_rf_50)
print(coverage_rate_overall_full_80)
print(coverage_rate_overall_rf_80)
```




```{r get-coverage-rate-class-nodule, warning=FALSE}
coverage_rate_by_class_full_50 = getCoverageRateByClassNodule(predintLogitFull, 50)
coverage_rate_by_class_rf_50 = getCoverageRateByClassNodule(predintLogitRF, 50)

coverage_rate_by_class_full_80 = getCoverageRateByClassNodule(predintLogitFull, 80)
coverage_rate_by_class_rf_80 = getCoverageRateByClassNodule(predintLogitRF, 80)

print(coverage_rate_by_class_full_50)
print(coverage_rate_by_class_rf_50)
print(coverage_rate_by_class_full_80)
print(coverage_rate_by_class_rf_80)

```