---
title: "RandomForestModeling"
author: "Ken Mawer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
source("helper_functions.R")
library(tidyverse)
library(maptree)
library(rpart.plot)
library(randomForest)
library(caret)
```

```{r get_data, include = FALSE}
# Get datasets
train <- read_csv("../Data/Meta/meta_annotation_info_train.csv")
holdo <- read_csv("../Data/Meta/meta_annotation_info_test.csv")

# Remove response variables and other irrelevant variables
process <- function(dataset) {
  dplyr::select(dataset,-Malignancy,-Malignancy_median_high,-Malignancy_median,-Malignancy_mean,-Malignancy_mode,-Malignancy_entropy,-Patient_id,-Nodule_no,-Nodule_id,-Annotation_no, -starts_with("Internal"),-Calcification_entropy,-Calcification_mean,-Calcification_median,-Calcification_median_high) %>%
    mutate(Is_cancer = as_factor(Is_cancer),Calcification = as_factor(Calcification),
           Calcification_mode = as_factor(Calcification_mode))
}

t <- process(train)
h <- process(holdo)
# Fixes missing factor levels
# Refer to https://stackoverflow.com/questions/24829674/r-random-forest-error-type-of-predictors-in-new-data-do-not-match
h <- rbind(t[1,],h)[-1,]
```

```{r analysis, include=FALSE}
# Exploratory data analysis
summary(train)
```

```{r tree, echo=FALSE}
set.seed(123)
tr <- tree::tree(Is_cancer~.,data=t)
rpart.plot(rpart(Is_cancer~.,data=t))
```

```{r accuracy_rate, include=FALSE}
# Accuracy rate function
# Inputs:
#   rf: A random forest model
#   dataset: The dataset
# Return:
#   A number between 0 and 1 of the proportion of correct classifications
rf_acc_rate <- function(rf,dataset) {
  pr <- predict(rf,dataset) == dataset$Is_cancer
  length(pr[pr]) / length(pr)
}
```

```{r, calc_error, echo=FALSE}
set.seed(123)
tx <- 1:nrow(t)
split1 <- tx[1:floor(nrow(t)/3)]
split2 <- tx[(floor(nrow(t)/3)+1):floor(2*nrow(t)/3)]
split3 <- tx[(floor(2*nrow(t)/3)+1):nrow(t)]
t1 <- t[-split1,];t2 <- t[-split2,];t3 <- t[-split3,]
h1 <- t[split1,]; h2 <- t[split2,]; h3 <- t[split3,]

mt <- c(38,19,9,4,2)
ns <- c(400,200,100,50,10,1)

ha1 <- c(); ha2 <- c(); ha3 <- c(); it <- c()
for (i in mt) {
  for (j in ns) {
    ha1 <- c(ha1,rf_acc_rate(randomForest(Is_cancer~.,data=t1,mtry = i,nodesize = j),h1))
    ha2 <- c(ha2,rf_acc_rate(randomForest(Is_cancer~.,data=t2,mtry = i,nodesize = j),h2))
    ha3 <- c(ha3,rf_acc_rate(randomForest(Is_cancer~.,data=t3,mtry = i,nodesize = j),h3))
    it <- c(it,paste(i,j))
  }
}
mean_holdout_accuracy <- matrix((ha1+ha2+ha3)/3,nrow=6)
rownames(mean_holdout_accuracy) <- ns
colnames(mean_holdout_accuracy) <- mt

```

```{r bestrf}
set.seed(123)
bestrf <- randomForest(Is_cancer~.,data=t,mtry = 9,nodesize = 10)
rf_acc_rate(bestrf,h)
```

I used the holdout method as the cross-validation error gave suggested I use a model that would result in lower holdout accuracy.

```{r interval_score,echo=FALSE}
# From Harry Joe's website
CategoryPredInterval = function(ProbMatrix, labels) {
  ncases = nrow(ProbMatrix)
  pred50 = rep(NA,ncases); pred80 = rep(NA,ncases)
  for(i in 1:ncases) {
    p = ProbMatrix[i,]
    ip = order(p,decreasing=T)
    pOrdered = p[ip] # decreasing order
    labelsOrdered = labels[ip] # decreasing order
    G = cumsum(pOrdered) # cumulative sum from largest
    k1 = min(which(G>=0.5)) # level1= 0.5
    k2 = min(which(G>=0.8)) # level2= 0.8
    pred1 = labelsOrdered[1:k1]; pred2 = labelsOrdered[1:k2]
    pred50[i] = paste(pred1,collapse="")
    pred80[i] = paste(pred2,collapse="")
  }
  list(pred50=pred50, pred80=pred80)
}

preds_probs <- bestrf %>%
  predict(newdata=h,type="prob") %>%
  as_tibble() %>%
  rename(T = True, F = False, N = No_consensus, A = Ambiguous) %>%
  as.matrix()
```

```{r coverage, echo = FALSE}
# Grabs the predicted probabilities
preds_probs2 <- bestrf %>%
  predict(newdata=h,type="prob") %>%
  as_tibble() %>%
  as.matrix()
```

Most important variables:

```{r variables, echo=FALSE}
# Grabs the most important variables by MeanDecreaseGini, with the most
# important variables being first
vars <- as.data.frame(bestrf$importance)
vars_important <- arrange(vars,desc(MeanDecreaseGini))

vars2 <- filter(vars_important,MeanDecreaseGini>=50)

vec <- rownames(vars2)
```

Updated function for prediction intervals:
```{r predint, include=FALSE}
predintRF = CategoryPredIntervalNodules(preds_probs, labels=c("Ambiguous","False","No_consensus", "True"))

lapply(getCoverageRateByClassNodule(predintRF,50),round,4)
lapply(getCoverageRateByClassNodule(predintRF,80),round,4)
```

```{r, overall_coverage_rate, echo = FALSE}
getOverallCoverageRateNodule(predintRF, 50)
getOverallCoverageRateNodule(predintRF, 80)
```

```{r table, echo=FALSE}
tx <- mutate(read_csv("../Data/Meta/meta_nodule_info_test.csv"),Is_cancer = recode(Is_cancer,True="T",False="F",No_consensus="N",Ambiguous="A"))

cpi <- CategoryPredInterval(preds_probs,c("T","F","N","A"))
table(tx$Is_cancer, predintRF$pred50)
table(tx$Is_cancer, predintRF$pred80)
```
